{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.mydataset import MyDataset\n",
    "from model.networks import heatmap_Encoder, flow_Encoder, encoder_3D, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'dataset'\n",
    "dataset = MyDataset(data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69624"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item = dataset[12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = data_item['heatmap'][1:]\n",
    "optical_flow = data_item['optical_flow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 17, 270, 480])\n",
      "torch.Size([11, 34, 270, 480])\n"
     ]
    }
   ],
   "source": [
    "print(heatmap.shape)\n",
    "print(optical_flow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:3\"\n",
    "input_h = torch.randn(32, 17, 270, 480).to(device)\n",
    "input_f = torch.randn(32, 34, 270, 480).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 125, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onwood/anaconda3/envs/bpe/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "hE = heatmap_Encoder().to(device)\n",
    "# h_feat = hE(heatmap)\n",
    "h_feat = hE(input_h)\n",
    "print(h_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 125, 230])\n"
     ]
    }
   ],
   "source": [
    "fE = flow_Encoder().to(device)\n",
    "# f_feat = fE(optical_flow)\n",
    "f_feat = fE(input_f)\n",
    "print(f_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 32, 125, 230])\n"
     ]
    }
   ],
   "source": [
    "hf_feat = torch.cat((h_feat, f_feat), dim=1).transpose(1,0)[None,...].to(device)\n",
    "print(hf_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onwood/anaconda3/envs/bpe/lib/python3.12/site-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv3d(\n"
     ]
    }
   ],
   "source": [
    "e3D = encoder_3D().to(device)\n",
    "motion_feature = e3D(hf_feat)\n",
    "print(motion_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 17, 2])\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder().to(device)\n",
    "print(decoder(motion_feature).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# m = nn.Conv1d(16, 33, 3, stride=2)\n",
    "# input = torch.randn(20, 16, 50)\n",
    "# output = m(input)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onwood/anaconda3/envs/bpe/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 125, 230])\n",
      "torch.Size([32, 3, 125, 230])\n",
      "torch.Size([1, 6, 32, 125, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onwood/anaconda3/envs/bpe/lib/python3.12/site-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv3d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n",
      "torch.Size([32, 17, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model.networks import heatmap_Encoder, flow_Encoder, encoder_3D, Decoder\n",
    "\n",
    "device = \"cuda:3\"\n",
    "input_h = torch.randn(32, 17, 270, 480).to(device)\n",
    "input_f = torch.randn(32, 34, 270, 480).to(device)\n",
    "\n",
    "hE = heatmap_Encoder().to(device)\n",
    "# h_feat = hE(heatmap)\n",
    "h_feat = hE(input_h)\n",
    "print(h_feat.shape)\n",
    "\n",
    "fE = flow_Encoder().to(device)\n",
    "# f_feat = fE(optical_flow)\n",
    "f_feat = fE(input_f)\n",
    "print(f_feat.shape)\n",
    "\n",
    "hf_feat = torch.cat((h_feat, f_feat), dim=1).transpose(1,0)[None,...].to(device)\n",
    "print(hf_feat.shape)\n",
    "\n",
    "e3D = encoder_3D().to(device)\n",
    "motion_feature = e3D(hf_feat)\n",
    "print(motion_feature.shape)\n",
    "\n",
    "decoder = Decoder().to(device)\n",
    "print(decoder(motion_feature).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
